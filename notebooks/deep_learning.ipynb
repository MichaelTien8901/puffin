{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# Deep Learning for Trading - Chapters 16-21\n",
    "\n",
    "This notebook covers the deep learning cluster from the Puffin project, demonstrating\n",
    "feedforward networks, CNNs, LSTMs, autoencoders, GANs, and deep reinforcement learning\n",
    "for algorithmic trading applications.\n",
    "\n",
    "**Chapters covered:**\n",
    "- Ch 16: Deep learning fundamentals (feedforward NNs, training utilities)\n",
    "- Ch 17: CNNs for financial time series\n",
    "- Ch 18: RNNs/LSTMs for multivariate time series\n",
    "- Ch 19: Autoencoders (standard, denoising, variational)\n",
    "- Ch 20: GANs for synthetic data generation\n",
    "- Ch 21-22: Deep RL (Q-learning, DQN, DDQN, PPO trading agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ffn-md",
   "metadata": {},
   "source": [
    "## 1. Feedforward Neural Networks (Ch 16)\n",
    "\n",
    "The simplest deep learning architecture for trading: a multi-layer feedforward network\n",
    "that maps feature vectors to return predictions. `FeedforwardNet` is the raw PyTorch\n",
    "module, while `TradingFFN` wraps it with a scikit-learn-style `.fit()` / `.predict()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ffn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from puffin.deep import FeedforwardNet, TradingFFN\n",
    "\n",
    "# --- Inspect the raw PyTorch module ---\n",
    "net = FeedforwardNet(input_dim=10, hidden_dims=[64, 32], output_dim=1, dropout=0.3)\n",
    "print(\"FeedforwardNet architecture:\")\n",
    "print(net)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in net.parameters()):,}\")\n",
    "\n",
    "# --- Train with the high-level wrapper ---\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 500, 10\n",
    "X = np.random.randn(n_samples, n_features).astype(np.float32)\n",
    "# Target: noisy linear combination (simulates return prediction)\n",
    "true_weights = np.random.randn(n_features)\n",
    "y = X @ true_weights + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "model = TradingFFN(input_dim=n_features, hidden_dims=[64, 32], output_dim=1, device='cpu')\n",
    "history = model.fit(X, y, epochs=50, lr=0.001, batch_size=64, verbose=True)\n",
    "\n",
    "# Predict on held-out data\n",
    "X_test = np.random.randn(50, n_features).astype(np.float32)\n",
    "y_test = X_test @ true_weights\n",
    "preds = model.predict(X_test)\n",
    "mse = np.mean((preds - y_test) ** 2)\n",
    "print(f\"\\nTest MSE: {mse:.4f}\")\n",
    "print(f\"Model metadata: {model.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-training-md",
   "metadata": {},
   "source": [
    "## 2. Training Utilities (Ch 16)\n",
    "\n",
    "Production training needs early stopping, learning-rate scheduling, and a reusable\n",
    "training loop. The `puffin.deep.training` module provides these as composable building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-training-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from puffin.deep import EarlyStopping, LRScheduler, training_loop, create_dataloaders, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Reuse the synthetic data from above\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    X, y, batch_size=64, val_split=0.2, random_seed=42\n",
    ")\n",
    "\n",
    "# Build a fresh model\n",
    "model_pt = FeedforwardNet(input_dim=10, hidden_dims=[64, 32], output_dim=1)\n",
    "optimizer = optim.Adam(model_pt.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Set up early stopping as a callback\n",
    "early_stop = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "def es_callback(epoch, train_loss, val_loss, model):\n",
    "    return early_stop(val_loss, model)\n",
    "\n",
    "# Set up LR scheduler\n",
    "scheduler = LRScheduler(optimizer, schedule_type='step', step_size=10, gamma=0.5)\n",
    "\n",
    "def lr_callback(epoch, train_loss, val_loss, model):\n",
    "    scheduler.step()\n",
    "    return False\n",
    "\n",
    "# Run the generic training loop with both callbacks\n",
    "history = training_loop(\n",
    "    model=model_pt,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=60,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    callbacks=[lr_callback, es_callback],\n",
    "    device=torch.device('cpu'),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining stopped after {len(history['train_loss'])} epochs\")\n",
    "print(f\"Best val loss: {early_stop.best_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-cnn-md",
   "metadata": {},
   "source": [
    "## 3. CNN for Time Series (Ch 17)\n",
    "\n",
    "1D convolutions slide learnable filters over a price/feature sequence, detecting\n",
    "local patterns such as momentum bursts or mean-reversion setups. `Conv1DNet` stacks\n",
    "multiple conv layers with max-pooling before a fully-connected head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-cnn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from puffin.deep import Conv1DNet\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate a price series with trend + noise\n",
    "n_steps = 500\n",
    "raw_prices = np.cumsum(np.random.randn(n_steps) * 0.02) + 100\n",
    "\n",
    "# Create sliding-window sequences (lookback=20, 1 feature)\n",
    "lookback = 20\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(lookback, len(raw_prices)):\n",
    "    X_seq.append(raw_prices[i - lookback:i])\n",
    "    y_seq.append(raw_prices[i])\n",
    "\n",
    "X_seq = np.array(X_seq, dtype=np.float32).reshape(-1, lookback, 1)  # (N, seq, channels)\n",
    "y_seq = np.array(y_seq, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "# Instantiate and inspect\n",
    "cnn = Conv1DNet(input_channels=1, seq_length=lookback, n_filters=[32, 64], kernel_sizes=[3, 3])\n",
    "print(\"Conv1DNet architecture:\")\n",
    "print(cnn)\n",
    "print(f\"Parameters: {sum(p.numel() for p in cnn.parameters()):,}\")\n",
    "\n",
    "# Quick forward pass sanity check\n",
    "sample = torch.FloatTensor(X_seq[:8])\n",
    "out = cnn(sample)\n",
    "print(f\"\\nInput shape:  {sample.shape}  ->  Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lstm-md",
   "metadata": {},
   "source": [
    "## 4. LSTM Networks (Ch 18)\n",
    "\n",
    "LSTMs maintain a hidden state across time steps, making them well-suited for\n",
    "sequential financial data. `TradingLSTM` handles a single univariate series,\n",
    "while `MultivariateLSTM` accepts a DataFrame of features and predicts a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lstm-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from puffin.deep import TradingLSTM, MultivariateLSTM\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Univariate LSTM ---\n",
    "series = np.cumsum(np.random.randn(300) * 0.5) + 100\n",
    "\n",
    "lstm = TradingLSTM()\n",
    "history = lstm.fit(series, lookback=20, epochs=30, lr=0.001, batch_size=32)\n",
    "\n",
    "# Forecast the next 5 steps\n",
    "forecast = lstm.predict(series, steps=5)\n",
    "print(f\"\\nLast 3 actual values:  {series[-3:]}\")\n",
    "print(f\"5-step forecast:       {forecast}\")\n",
    "\n",
    "# --- Multivariate LSTM (concept) ---\n",
    "import pandas as pd\n",
    "\n",
    "n = 300\n",
    "df = pd.DataFrame({\n",
    "    'open':   np.cumsum(np.random.randn(n) * 0.3) + 100,\n",
    "    'high':   np.cumsum(np.random.randn(n) * 0.3) + 101,\n",
    "    'low':    np.cumsum(np.random.randn(n) * 0.3) + 99,\n",
    "    'close':  np.cumsum(np.random.randn(n) * 0.3) + 100,\n",
    "    'volume': np.abs(np.random.randn(n) * 1000) + 5000,\n",
    "})\n",
    "\n",
    "mv_lstm = MultivariateLSTM()\n",
    "mv_history = mv_lstm.fit(\n",
    "    df, target_col='close', lookback=20, epochs=30, lr=0.001,\n",
    "    hidden_dims=[64, 32]\n",
    ")\n",
    "\n",
    "pred = mv_lstm.predict(df)\n",
    "print(f\"\\nMultivariate LSTM next-step prediction: {pred[0]:.2f}\")\n",
    "print(f\"Actual last close: {df['close'].iloc[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ae-md",
   "metadata": {},
   "source": [
    "## 5. Autoencoders (Ch 19)\n",
    "\n",
    "Autoencoders learn a compressed latent representation of the input. Three variants are\n",
    "provided:\n",
    "\n",
    "- **Autoencoder** -- standard encoder-decoder for dimensionality reduction\n",
    "- **DenoisingAutoencoder** -- adds Gaussian noise during training for robustness\n",
    "- **VAE** -- variational autoencoder with a probabilistic latent space, enabling\n",
    "  generation of new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ae-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from puffin.deep import Autoencoder, DenoisingAutoencoder, VAE, AETrainer\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Synthetic market features (50 dims -> compress to 8)\n",
    "n_samples, input_dim, encoding_dim = 400, 50, 8\n",
    "X_ae = np.random.randn(n_samples, input_dim).astype(np.float32)\n",
    "\n",
    "trainer = AETrainer(device='cpu')\n",
    "\n",
    "# --- Standard Autoencoder ---\n",
    "ae = Autoencoder(input_dim=input_dim, encoding_dim=encoding_dim, hidden_dims=[128, 64])\n",
    "ae_hist = trainer.fit(ae, X_ae, epochs=30, lr=0.001, verbose=True)\n",
    "features_ae = trainer.extract_features(ae, X_ae)\n",
    "print(f\"\\nAutoencoder: {input_dim}D -> {features_ae.shape[1]}D latent\")\n",
    "\n",
    "# --- Denoising Autoencoder ---\n",
    "dae = DenoisingAutoencoder(input_dim=input_dim, encoding_dim=encoding_dim, noise_factor=0.3)\n",
    "dae_hist = trainer.fit(dae, X_ae, epochs=30, lr=0.001, verbose=False)\n",
    "features_dae = trainer.extract_features(dae, X_ae)\n",
    "print(f\"DenoisingAE: {input_dim}D -> {features_dae.shape[1]}D latent  (final loss {dae_hist['val_loss'][-1]:.4f})\")\n",
    "\n",
    "# --- Variational Autoencoder ---\n",
    "vae = VAE(input_dim=input_dim, latent_dim=encoding_dim, hidden_dims=[128, 64])\n",
    "vae_hist = trainer.fit(vae, X_ae, epochs=30, lr=0.001, verbose=False)\n",
    "features_vae = trainer.extract_features(vae, X_ae)\n",
    "print(f\"VAE:         {input_dim}D -> {features_vae.shape[1]}D latent  (final loss {vae_hist['val_loss'][-1]:.4f})\")\n",
    "\n",
    "# Generate new samples from the VAE\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    generated = vae.sample(n=5, device=torch.device('cpu')).numpy()\n",
    "print(f\"\\nGenerated {generated.shape[0]} synthetic feature vectors of dim {generated.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-gan-md",
   "metadata": {},
   "source": [
    "## 6. GANs for Synthetic Data (Ch 20)\n",
    "\n",
    "A GAN pits a Generator against a Discriminator to produce realistic synthetic\n",
    "market data. This is useful for data augmentation, stress testing, and privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gan-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from puffin.deep import GAN, SyntheticDataEvaluator\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Real data: 5-dim feature vectors drawn from a mixture of Gaussians\n",
    "data_dim = 5\n",
    "cluster_a = np.random.randn(200, data_dim) * 0.5 + 1.0\n",
    "cluster_b = np.random.randn(200, data_dim) * 0.5 - 1.0\n",
    "real_data = np.vstack([cluster_a, cluster_b]).astype(np.float32)\n",
    "np.random.shuffle(real_data)\n",
    "\n",
    "# Train a GAN\n",
    "gan = GAN(latent_dim=16, data_dim=data_dim, device='cpu')\n",
    "gan_hist = gan.train(real_data, epochs=50, batch_size=64, lr=0.0002, verbose=True)\n",
    "\n",
    "# Generate synthetic samples\n",
    "synthetic_data = gan.generate(n_samples=400)\n",
    "print(f\"\\nGenerated shape: {synthetic_data.shape}\")\n",
    "print(f\"Real mean:      {real_data.mean(axis=0)[:3]}\")\n",
    "print(f\"Synthetic mean: {synthetic_data.mean(axis=0)[:3]}\")\n",
    "\n",
    "# Evaluate quality\n",
    "evaluator = SyntheticDataEvaluator()\n",
    "dist_results = evaluator.compare_distributions(real_data, synthetic_data)\n",
    "print(f\"\\nAvg KS statistic:  {dist_results['avg_ks_statistic']:.4f}\")\n",
    "print(f\"Avg mean diff:     {dist_results['avg_mean_diff']:.4f}\")\n",
    "print(f\"Avg std diff:      {dist_results['avg_std_diff']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-rl-md",
   "metadata": {},
   "source": [
    "## 7. Deep Reinforcement Learning (Ch 21)\n",
    "\n",
    "RL agents learn a trading policy by interacting with a simulated environment.\n",
    "The `puffin.rl` module provides:\n",
    "\n",
    "- **QLearningAgent** -- tabular Q-learning for discretized state spaces\n",
    "- **DQNAgent / DDQNAgent** -- deep Q-networks with experience replay\n",
    "- **TradingEnvironment** -- a Gymnasium-compatible env with configurable reward types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-rl-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from puffin.rl import QLearningAgent, DQNAgent, DDQNAgent, TradingEnvironment, evaluate_agent\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic prices (random walk with drift)\n",
    "prices = np.cumsum(np.random.randn(500) * 0.5) + 100\n",
    "prices = np.maximum(prices, 1.0)  # keep positive\n",
    "\n",
    "# --- TradingEnvironment walkthrough ---\n",
    "env = TradingEnvironment(prices, initial_cash=100_000, commission=0.001, reward_type='pnl')\n",
    "obs, info = env.reset()\n",
    "print(f\"Observation shape: {obs.shape}\")\n",
    "print(f\"Action space: {env.action_space}  (0=sell, 1=hold, 2=buy)\")\n",
    "print(f\"Initial info: {info}\")\n",
    "\n",
    "# --- Tabular Q-Learning (discretized) ---\n",
    "# For Q-learning we need integer states -- use a tiny example\n",
    "q_agent = QLearningAgent(n_states=100, n_actions=3, lr=0.1, gamma=0.99, epsilon=1.0)\n",
    "print(f\"\\nQ-table shape: {q_agent.q_table.shape}\")\n",
    "\n",
    "# Manually run a few updates to demonstrate the API\n",
    "q_agent.update(state=0, action=2, reward=10.0, next_state=1, done=False)\n",
    "q_agent.update(state=1, action=1, reward=-2.0, next_state=2, done=False)\n",
    "print(f\"Q[0, buy] after update: {q_agent.q_table[0, 2]:.2f}\")\n",
    "\n",
    "# --- DQN Agent ---\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "dqn = DQNAgent(\n",
    "    state_dim=obs_dim, action_dim=3, lr=1e-3,\n",
    "    gamma=0.99, buffer_size=5000, batch_size=32,\n",
    "    target_update=50, device='cpu'\n",
    ")\n",
    "\n",
    "# Train for a small number of episodes (demo only)\n",
    "rewards_dqn = dqn.train(env, episodes=20, epsilon_start=1.0, epsilon_decay=0.95, verbose=False)\n",
    "print(f\"\\nDQN -- episodes: {len(rewards_dqn)}, mean reward: {np.mean(rewards_dqn):.2f}\")\n",
    "\n",
    "# --- Double DQN ---\n",
    "ddqn = DDQNAgent(\n",
    "    state_dim=obs_dim, action_dim=3, lr=1e-3,\n",
    "    gamma=0.99, buffer_size=5000, batch_size=32,\n",
    "    target_update=50, device='cpu'\n",
    ")\n",
    "rewards_ddqn = ddqn.train(env, episodes=20, epsilon_start=1.0, epsilon_decay=0.95, verbose=False)\n",
    "print(f\"DDQN -- episodes: {len(rewards_ddqn)}, mean reward: {np.mean(rewards_ddqn):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ppo-md",
   "metadata": {},
   "source": [
    "## 8. PPO Trading Agent (Ch 22)\n",
    "\n",
    "`PPOTrader` wraps stable-baselines3 PPO for on-policy training. It requires\n",
    "`stable-baselines3` to be installed. The cell below demonstrates the API\n",
    "and evaluation workflow; set `run_ppo = True` to actually train (requires the\n",
    "dependency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ppo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ppo = False  # flip to True if stable-baselines3 is installed\n",
    "\n",
    "if run_ppo:\n",
    "    from puffin.rl import PPOTrader, evaluate_agent, TradingEnvironment\n",
    "\n",
    "    np.random.seed(42)\n",
    "    prices_ppo = np.cumsum(np.random.randn(1000) * 0.5) + 100\n",
    "    prices_ppo = np.maximum(prices_ppo, 1.0)\n",
    "    env_ppo = TradingEnvironment(prices_ppo, initial_cash=100_000)\n",
    "\n",
    "    ppo = PPOTrader(env_ppo, learning_rate=3e-4, n_steps=256, batch_size=64, verbose=0)\n",
    "    ppo.train(total_timesteps=5000)\n",
    "\n",
    "    results = evaluate_agent(ppo, env_ppo, n_episodes=5)\n",
    "    print(\"PPO evaluation results:\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "else:\n",
    "    print(\"PPO demo skipped (set run_ppo = True to execute).\")\n",
    "    print(\"\\nPPOTrader API summary:\")\n",
    "    print(\"  ppo = PPOTrader(env, learning_rate=3e-4, n_steps=2048)\")\n",
    "    print(\"  ppo.train(total_timesteps=100_000)\")\n",
    "    print(\"  action = ppo.predict(obs, deterministic=True)\")\n",
    "    print(\"  results = ppo.evaluate(env, n_episodes=10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary-md",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Module | Class / Function | Purpose |\n",
    "|--------|-----------------|--------|\n",
    "| `puffin.deep` | `FeedforwardNet`, `TradingFFN` | Feedforward NN for return prediction |\n",
    "| `puffin.deep` | `EarlyStopping`, `LRScheduler`, `training_loop` | Reusable training utilities |\n",
    "| `puffin.deep` | `Conv1DNet`, `TradingCNN` | 1D CNN for sequential pattern detection |\n",
    "| `puffin.deep` | `TradingLSTM`, `MultivariateLSTM` | LSTM for univariate / multivariate time series |\n",
    "| `puffin.deep` | `Autoencoder`, `DenoisingAutoencoder`, `VAE` | Latent representations and generation |\n",
    "| `puffin.deep` | `GAN`, `TimeGAN`, `SyntheticDataEvaluator` | Synthetic data generation and evaluation |\n",
    "| `puffin.rl` | `QLearningAgent` | Tabular Q-learning |\n",
    "| `puffin.rl` | `DQNAgent`, `DDQNAgent` | Deep Q-Network agents |\n",
    "| `puffin.rl` | `TradingEnvironment` | Gymnasium trading environment |\n",
    "| `puffin.rl` | `PPOTrader`, `evaluate_agent` | PPO agent and evaluation toolkit |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
